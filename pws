#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Import libraries
import re
import csv
import requests
import urllib.request
#import time
from bs4 import BeautifulSoup

#URL
url = ""

# Connect to the URL
resp = requests.get(url)

# Parse HTML and save to BeautifulSoup object
soup = BeautifulSoup(resp.text, "html.parser")

#Guardamos todo
for j in soup.find_all(class_="campo_tabla"):
	with open("p.csv", mode = "a", encoding = "utf-8") as p_file:
		p_writer = csv.writer(p_file, delimiter = "\t")
		p_writer.writerow([
			re.sub("\t|\r?\n", "", j.find_all("td")[0].text.strip()),
      re.sub("\t|\r?\n", "", j.find_all("td")[1].text.strip())			
			])
